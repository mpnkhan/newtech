<!doctype html>
<html>
<head>
  <title>Using Microsoft Face Detection API</title>

  <style>
video {
  width: 400px;
  height: 300px;
  border: 1px solid black;
    box-shadow: 2px 2px 3px black;
}
#screenshot-img {
    width: 400px;
    height: 300px;
}

button {
    display: inline-block;
    text-decoration: none;
    color: #fff;
    font-weight: bold;
    background-color: #538fbe;
    font-size: 20px;
    border: 1px solid #2d6898;
    background-image: linear-gradient(bottom, rgb(73,132,180) 0%, rgb(97,155,203) 100%);
    background-image: -o-linear-gradient(bottom, rgb(73,132,180) 0%, rgb(97,155,203) 100%);
    background-image: -moz-linear-gradient(bottom, rgb(73,132,180) 0%, rgb(97,155,203) 100%);
    background-image: -webkit-linear-gradient(bottom, rgb(73,132,180) 0%, rgb(97,155,203) 100%);
    background-image: -ms-linear-gradient(bottom, rgb(73,132,180) 0%, rgb(97,155,203) 100%);
 
    background-image: -webkit-gradient(
        linear,
        left bottom,
        left top,
        color-stop(0, rgb(73,132,180)),
        color-stop(1, rgb(97,155,203))
    );
    -webkit-border-radius: 5px;
    -moz-border-radius: 5px;
    border-radius: 5px;
    text-shadow: 0px -1px 0px rgba(0,0,0,.5);
    -webkit-box-shadow: 0px 6px 0px #2b638f, 0px 3px 15px rgba(0,0,0,.4), inset 0px 1px 0px rgba(255,255,255,.3), inset 0px 0px 3px rgba(255,255,255,.5);
    -moz-box-shadow: 0px 6px 0px #2b638f, 0px 3px 15px rgba(0,0,0,.4), inset 0px 1px 0px rgba(255,255,255,.3), inset 0px 0px 3px rgba(255,255,255,.5);
    box-shadow: 0px 6px 0px #2b638f, 0px 3px 15px rgba(0,0,0,.4), inset 0px 1px 0px rgba(255,255,255,.3), inset 0px 0px 3px rgba(255,255,255,.5);
}

//tracking/face_alignment_image
.rect, .circle {
    left: -1000px;
    position: absolute;
    top: -1000px;
  }
  .rect{
    border: 2px solid #a64ceb;
  }
  .circle {
    border-radius: 50%;
    box-shadow: 0px 0px 3px rgba(0,0,0,0.3);
  }

/*  #screenshot-img {
    position: absolute;
    top: 50%;
    left: 50%;
    margin: -200px 0 0 -200px;
  }*/
</style>
 </head>
 <body>

  <div id="screenshot" style="text-align:center;">
  <video class="videostream" autoplay></video>

      <canvas style="display:none;"></canvas>
  <img id="screenshot-img">
  <p><button class="capture-button">Start</button>
  <p><button id="screenshot-button" disabled>Detect Face</button></p>

  <p id="desc" style="font-size: 19px;"></p>
  <p>
     <textarea id="responseTextArea" style="width:580px; height:400px;"> </textarea>
  </p>

</div>


  <script src="../tracking/build/tracking.js"></script>
  <script src="../tracking/build/data/face-min.js"></script>
  <script src="../tracking/src/alignment/training/Landmarks.js"></script>
  <script src="../tracking/src/alignment/training/Regressor.js"></script>
  
  <!-- <script src="../tracking/node_modules/dat.gui/build/dat.gui.min.js"></script> -->


<script>
function handleError(error) {
  console.error('navigator.getUserMedia error: ', error);
}
const constraints = {video: true};


(function() {
  const captureVideoButton =
    document.querySelector('#screenshot .capture-button');
  const screenshotButton = document.querySelector('#screenshot-button');
  const img = document.querySelector('#screenshot img');
  var photoanalze= null;
  const video = document.querySelector('#screenshot video');

  const canvas = document.createElement('canvas');

  captureVideoButton.onclick = function() {
    navigator.mediaDevices.getUserMedia(constraints).
      then(handleSuccess).catch(handleError);
  };

  screenshotButton.onclick = video.onclick = function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    canvas.getContext('2d').drawImage(video, 0, 0);
    var data = canvas.toDataURL('image/png');
    img.src = data;
    photoanalze= data;
    // setTimeout(function(){ tracking()} , 3000);
    postData(photoanalze);

//
  };

  function handleSuccess(stream) {
    screenshotButton.disabled = false;
    video.srcObject = stream;
    // postData(photoanalze);
  }

  //tracking
  function tracking(){
    var tracker = new window.tracking.LandmarksTracker();
    var img = document.getElementById('screenshot-img')
      tracker.setInitialScale(4);
      tracker.setStepSize(2);
      tracker.setEdgesDensity(0.1);

      window.tracking.track('#screenshot-img', tracker);

      tracker.on('track', function(event) {

        if(!event.data) return;

        event.data.faces.forEach(function(rect) {
          window.plot(rect.x, rect.y, rect.width, rect.height);
        });

        event.data.landmarks.forEach(function(landmarks) {
          for(var i=0; i < landmarks.length; i++){
            window.plotLandmark(landmarks[i][0], landmarks[i][1], 2, '#44ABDA');
          }
        });

      });

      window.plot = function(x, y, w, h) {
        var rect = document.createElement('div');
        document.querySelector('#screenshot').appendChild(rect);
        rect.classList.add('rect');
        rect.style.width = w + 'px';
        rect.style.height = h + 'px';
        rect.style.left = (img.offsetLeft + x) + 'px';
        rect.style.top = (img.offsetTop + y) + 'px';
      };

      window.plotLandmark = function(x,y, radius, color){
        var circle = document.createElement('div');
        document.querySelector('#screenshot').appendChild(circle);
        circle.classList.add('circle');
        circle.style.backgroundColor = color;
        circle.style.width = (radius*2) + 'px';
        circle.style.height = (radius*2) + 'px';
        circle.style.left = (img.offsetLeft + x) + 'px';
        circle.style.top = (img.offsetTop + y) + 'px';
      }
  }

  //end tracking 

function makeblob (dataURL) {
    var BASE64_MARKER = ';base64,';
    if (dataURL.indexOf(BASE64_MARKER) == -1) {
        var parts = dataURL.split(',');
        var contentType = parts[0].split(':')[1];
        var raw = decodeURIComponent(parts[1]);
        return new Blob([raw], { type: contentType });
    }
    var parts = dataURL.split(BASE64_MARKER);
    var contentType = parts[0].split(':')[1];
    var raw = window.atob(parts[1]);
    var rawLength = raw.length;

    var uInt8Array = new Uint8Array(rawLength);

    for (var i = 0; i < rawLength; ++i) {
        uInt8Array[i] = raw.charCodeAt(i);
    }

    return new Blob([uInt8Array], { type: contentType });
}
serialize = function(obj) {
  var str = [];
  for (var p in obj)
    if (obj.hasOwnProperty(p)) {
      str.push(encodeURIComponent(p) + "=" + encodeURIComponent(obj[p]));
    }
  return str.join("&");
}
  function postData(data) {
   var params = {
        "returnFaceId": "true",
        "returnFaceLandmarks": "false",
        "returnFaceAttributes":
            "age,gender,headPose,smile,facialHair,glasses,emotion," +
            "hair,makeup,occlusion,accessories,blur,exposure,noise"
    };

  let url = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect?' + serialize(params);
  // let url = 'https://westus.api.cognitive.microsoft.com/emotion/v1.0/recognize?' + serialize(params);

  return fetch(url, {
    body: makeblob(data), 
    cache: 'no-cache',    // *default, no-cache, reload, force-cache, only-if-cached
    headers: {
      'Content-Type': 'application/octet-stream',
      // 'Ocp-Apim-Subscription-Key': '55c111fd66f340289347a12ba4063c73'   //recognize
      'Ocp-Apim-Subscription-Key': '199d7deaa6b549c2852aea5642049481'   
    },
    method: 'POST'
  })
  .then(response => response.json()) // parses response to JSON
  .then(function(myJson) { 
    var faceAttributes = myJson[0].faceAttributes;
    var age = faceAttributes.age;
    var gender = faceAttributes.gender;
    var facialHair = (faceAttributes.facialHair.beard>0) ? ' with  beard ':'' 
    facialHair += (faceAttributes.facialHair.moustache>0)? ' has moustache ':'';

    var res= '<strong> Detected ' + gender +' of ' + age + 'years'  + facialHair +'</strong>';
    document.getElementById('desc').innerHTML= res;

      var resultDiv = document.getElementById('responseTextArea');
      resultDiv.value= JSON.stringify(myJson, null, 2);
      
  });
}
})();
</script>

</body>
</html>